import os
import pandas as pd

def get_files_from_directory(directory_path):
    try:
        # Get the list of files in the specified directory
        files = [f for f in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, f))]
        return files
    except FileNotFoundError:
        print(f"Directory not found: {directory_path}")
        return []
    


#def combine_csv(file,master):



def main(folder, output_file):

    # Load files
    files = get_files_from_directory(folder)
    if files:
        
        # Initialize an empty DataFrame to store the combined data
        combined_df = pd.DataFrame()
        for file in files:
            f = str(folder+"/"+file)
            df = pd.read_csv(f, usecols=[0], header=None, skiprows=[0])
            num_lines = len(df)
            print(f"> {f} w\: {num_lines} IPs")
            
        
    else: print("No files found in the specified directory.")



def merge_csv_files(files, output_file):
    try:
        # Initialize an empty list to store DataFrames
        dfs = []

        # Loop through each CSV file and read it into a DataFrame
        for file in files:
            if os.path.exists(file):  # Check if the file exists
                df = pd.read_csv(file)
                dfs.append(df)
            else:
                print(f"Warning: File not found - {file}")

        # Concatenate (stack) the DataFrames vertically
        master_df = pd.concat(dfs, ignore_index=True)

        # Write the concatenated data to the output CSV file
        master_df.to_csv(output_file, index=False)

        print(f"CSV files merged. Output written to: {output_file}")

    except Exception as e:
        print(f"Error: {e}")


if __name__ == "__main__":
    #main("splunk_dump", "anomali.csv")
    input_csv_files = ['x.csv','y.csv']
    output_csv_file = 'anomali.csv'
    merge_csv_files(input_csv_files, output_csv_file)

    df = pd.read_csv(output_csv_file)

    # Remove duplicates based on all columns
    deduplicated_df = df.drop_duplicates()

    # Write the deduplicated data to the output CSV file
    deduplicated_df.to_csv(output_csv_file, index=False)
